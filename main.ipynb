{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up logging, device and seed\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "seed = 69\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and Preprocess Data\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "codebook = pd.read_csv('codebook.csv')\n",
    "\n",
    "logger.info(\"Data loaded successfully\")\n",
    "logger.info(\"Original Training data shape: %s\", str(train_data.shape))\n",
    "logger.info(\"Original Predication data shape: %s\", str(test_data.shape))\n",
    "\n",
    "X = train_data.drop(columns=['target'])\n",
    "y = train_data['target']\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, Y_temp = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, Y_temp, test_size=0.33, random_state=seed)\n",
    "\n",
    "logger.info(\"Shape of Train data: %s\", str(X_train.shape))\n",
    "logger.info(\"Shape of Validation data: %s\", str(X_val.shape))\n",
    "logger.info(\"Shape of Test data: %s\", str(X_test.shape))\n",
    "\n",
    "# Normalize data?\n",
    "# TODO\n",
    "def normalize_data(data):\n",
    "    return (data - data.mean()) / data.std()\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensors and move to device\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the Neural Network\n",
    "\n",
    "# hier hebben we echt veel opties, dus ik heb simpele ffn gekopieerd van deep learning course\n",
    "\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Large neural network with dropout and batch normalization\n",
    "# \"what do you mean it overfits lol\"\n",
    "class LargeNN(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.2):\n",
    "        super(LargeNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        if x is None:\n",
    "            logger.debug(\"Error after fc1 and bn1\")\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        if x is None:\n",
    "            logger.debug(\"Error after fc2 and bn2\")\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        if x is None:\n",
    "            logger.debug(\"Error after fc3 and bn3\")\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        if x is None:\n",
    "            logger.debug(\"Error after fc4 and bn4\")\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        if x is None:\n",
    "            logger.debug(\"Error after fc5\")\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 64\n",
    "nEpochs = 10 # deze sws wel omhoog maar ff voor snelheid nu :)\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_dim = X_train.shape[1]\n",
    "# model = FeedforwardNN(input_dim).to(device)\n",
    "model = LargeNN(input_dim).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the training and evaluation functions\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, print_every=1):\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # labels = labels.view(-1, 1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            logger.debug(f\"Model output shape: {outputs.shape}\")\n",
    "            logger.debug(f\"Label shape: {labels.shape}\")\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "        \n",
    "        # Calculate training accuracy for this epoch\n",
    "        train_accuracy = correct_preds / total_preds\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Validation accuracy at the end of each epoch\n",
    "        val_preds, val_labels = evaluate_model(model, val_loader)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            logger.info(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Time elapsed: {time.time() - start_time:.2f}s')\n",
    "\n",
    "    logger.info(f'Training complete. Total time elapsed: {time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time))}')\n",
    "    \n",
    "    return train_accuracies, val_accuracies\n",
    "\n",
    "        \n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return np.array(all_preds).flatten(), np.array(all_labels).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(train_accuracies, val_accuracies):\n",
    "    epochs = range(1, len(train_accuracies) + 1)\n",
    "    \n",
    "    plt.plot(epochs, train_accuracies, 'bo-', label='Training accuracy')\n",
    "    plt.plot(epochs, val_accuracies, 'ro-', label='Validation accuracy')\n",
    "    \n",
    "    plt.title('Training and Validation Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_accuracies, val_accuracies = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=nEpochs)\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plot_accuracies(train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Prepare test data\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_preds, val_labels = evaluate_model(model, val_loader)\n",
    "logger.info(f\"Validation Accuracy: {accuracy_score(val_labels, val_preds):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_preds, test_labels = evaluate_model(model, test_loader)\n",
    "logger.info(f\"Test Accuracy: {accuracy_score(test_labels, test_preds):.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "logger.info(f\"Classification Report:\\n{classification_report(test_labels, test_preds)}\")\n",
    "\n",
    "# Plot confusion matrix for test set\n",
    "plot_confusion_matrix(test_labels, test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier nog ff wat toevoegen zodat ons model ook de test data kan voorspellen en in predictions.txt zet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
